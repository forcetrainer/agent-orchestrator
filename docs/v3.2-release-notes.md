# System Prompt v3.2 Release Notes

**Date**: 2025-10-08
**Version**: v3.2 - Conciseness and Formatting
**Status**: Ready for Testing

---

## Summary

Version 3.2 addresses verbosity and formatting issues introduced by v3.1. While v3.1 fixed the execution pattern (agent now analyzes instead of delegates), it created information overload with walls of text and pre-written drafts. v3.2 teaches the agent to **distill to essence** rather than **document everything**.

## The Problem

**v3.1 Progress**: ✅ Agent analyzes (doesn't delegate)
**v3.1 Issue**: ❌ Too verbose, cluttered output

### Claude Code (clean, focused):
```
Based on Alex's intake, I can see the core issue is about RCA completion delays.
Here's what I'm seeing from the intake:
- Problem: RCAs not completed on time → delays mitigations → repeat outages
- Goal: Complete RCAs within 5 days of outage resolution
- Solution approach: Automated reminders + escalations

For the refined problem statement, you might want to ask John:
- "Can you describe a recent example where delayed RCA led to repeat outage?"
- "What's currently preventing timely completion?"
- "Beyond the 5-day target, what's the ultimate business outcome?"

Please input the refined problem statement with business context:
```

**Lines**: ~15
**Bullets**: 3 concise points
**Tone**: Natural, conversational

### App with v3.1 (verbose, cluttered):
```
I'll guide you through the requirements session by suggesting questions...

Summary (analysis of Alex's intake)
Problem: Root Cause Analyses (RCAs) are not completed in a timely manner,
causing repeat outages and delayed mitigations that impact service quality...
[continues for 200+ words]

Refined problem statement (draft) RCAs are frequently completed late or not
at all, resulting in repeat outages and unmitigated root causes. John wants...
[another 150+ words]

You might want to ask about:
- Who is the designated escalation contact or manager for overdue RCAs?
...
```

**Lines**: ~40+
**Issues**:
- Information overload (dumps all analysis)
- Creates "draft problem statement" (not requested)
- Robotic framing ("I'll guide you through...")
- Poor formatting (walls of text)
- Over-thorough instead of focused

## Root Cause

v3.1 said "show your work/analysis" but didn't specify:
- **How much** (essence vs comprehensive)
- **In what format** (bullets vs paragraphs)
- **What NOT to do** (no pre-written drafts)

The LLM interpreted as "be thorough" rather than "be concise."

## The Solution

Added new section: **CONCISENESS AND FORMATTING RULES - CRITICAL**

### Key Rules:

1. **DISTILL TO ESSENCE** (not information dump)
   - 3-5 key bullet points MAXIMUM
   - Each bullet ONE LINE (not paragraphs)
   - Focus on WHAT MATTERS, not comprehensive documentation

2. **USE CLEAN FORMATTING**
   - Use arrows (→) for cause/effect relationships
   - Keep bullets scannable (under 15 words when possible)
   - NO walls of text or multi-paragraph explanations
   - NO section headers like "Summary (analysis of...)"

3. **DO NOT PRE-WRITE DELIVERABLES**
   - Do NOT create drafts, statements, or documents unless explicitly asked
   - Analysis = showing you understand (3-5 bullets)
   - NOT = writing the deliverable for them

4. **NATURAL FRAMING**
   - Skip robotic intros like "I'll guide you through..."
   - Start naturally: "Based on [source], here's what I'm seeing:"
   - Be conversational, not procedural

### Added Critical Statement:

> "Your role is to show you UNDERSTAND the context (concise bullets), not to DOCUMENT everything you read (verbose summaries). Be a helpful analyst, not a transcription service."

## Key Changes

**File**: `lib/agents/prompts/system-prompt.md`

**New Section**: CONCISENESS AND FORMATTING RULES - CRITICAL (~50 lines)

**Additions**:
- 4 formatting rules with concrete examples
- ✅ GOOD example (3 bullets, natural framing)
- ❌ BAD example (verbose analysis dump, pre-written draft)
- Updated USING LOADED CONTEXT: "Distill to 3-5 essential bullets (not comprehensive summaries)"
- Updated GENERAL CONVERSATIONAL RULES: "Be concise: favor clarity and scannability over thoroughness"

## Expected Behavior Changes

### Before v3.2 (v3.1):
```
I'll guide you through the requirements session...

Summary (analysis of Alex's intake)
Problem: Root Cause Analyses (RCAs) are not completed in a timely manner...
[200+ words of detailed analysis]

Refined problem statement (draft)
RCAs are frequently completed late or not at all...
[150+ words of pre-written draft]
```

### After v3.2:
```
Based on Alex's intake, here's what I'm seeing:
- Problem: RCAs not completed on time → delays mitigations → repeat outages
- Goal: Complete RCAs within 5 days of outage resolution
- Solution approach: Automated reminders + escalations

For the refined problem statement, you might want to ask John:
- "Can you describe a recent example where delayed RCA led to repeat outage?"
- "What's currently preventing timely completion?"
- "Beyond the 5-day target, what's the ultimate business outcome?"

Please input the refined problem statement with business context:
```

### Comparison:

| Aspect | v3.1 | v3.2 (Expected) |
|--------|------|-----------------|
| **Line count** | 40+ lines | ~15 lines |
| **Analysis format** | Multi-paragraph summaries | 3-5 bullet points |
| **Bullet length** | Multiple sentences | One line each |
| **Pre-written content** | Creates drafts | Never (unless asked) |
| **Framing** | "I'll guide you..." | "Here's what I'm seeing:" |
| **Scannability** | Low (walls of text) | High (clean bullets) |
| **Match to Claude Code** | Partial (correct pattern, wrong format) | Close (pattern + format) |

## Testing

### Validation Script
```bash
npx tsx scripts/test-system-prompt.ts
```

Expected output:
```
✅ v3.2 Conciseness and Formatting features detected
✅ All checks passed!
```

### Behavioral Test Scenario

**Setup**: Casey deep-dive workflow, Step 2 (same as v3.1 test)

**Step 2 Expected Output**:
- ✅ Shows "Step 2: Refine problem statement"
- ✅ Natural opening: "Based on Alex's intake, here's what I'm seeing:"
- ✅ 3-5 concise bullets (one line each)
- ✅ Uses arrows (→) for cause/effect
- ✅ NO section headers like "Summary (analysis of...)"
- ✅ NO pre-written draft problem statement
- ✅ Provides contextual questions naturally
- ✅ THEN asks for refined statement
- ✅ Total output: ~15 lines (not 40+)

### Comparison Test

Same scenario, compare:
1. **Claude Code** (baseline)
2. **App with v3.1** (verbose, cluttered)
3. **App with v3.2** (should be concise, clean)

Metrics:
- Line count (should match Claude Code ~15 lines)
- Bullet count (3-5 essential points)
- Bullet length (one line each)
- No pre-written drafts
- Natural framing

## Migration Path

v3.2 is a DROP-IN REPLACEMENT for v3.1. No code changes required.

**To Deploy**:
1. ✅ Template already updated: `lib/agents/prompts/system-prompt.md`
2. ✅ systemPromptBuilder.ts loads from template
3. ✅ Test script updated for v3.2 detection
4. 🔄 **Restart dev server** to pick up new template
5. 🔄 Test with Casey deep-dive workflow

**To Rollback** (if needed):
```bash
cp lib/agents/prompts/versions/v3.1-action-execution.md \
   lib/agents/prompts/system-prompt.md
```

## Files Modified

```
lib/agents/prompts/
├── CHANGELOG.md                               # Added v3.2 entry
├── README.md                                  # Updated current version
├── system-prompt.md                           # Updated to v3.2
└── versions/
    └── v3.2-conciseness-formatting.md         # New version snapshot

lib/agents/
└── systemPromptBuilder.ts                     # Updated version comments

scripts/
└── test-system-prompt.ts                      # Updated to detect v3.2

docs/
└── v3.2-release-notes.md                      # This file
```

## Success Criteria

v3.2 is successful if:

1. ✅ Test script passes (validates v3.2 features present)
2. 🔄 Casey Step 2 outputs ~15 lines (not 40+)
3. 🔄 Analysis is 3-5 bullets, one line each
4. 🔄 Uses arrows (→) for cause/effect
5. 🔄 NO pre-written drafts
6. 🔄 Natural framing (no robotic intros)
7. 🔄 Closely matches Claude Code's conciseness

## Iteration Progress

| Version | Focus | Status |
|---------|-------|--------|
| v3.0 | Context-aware guidance | ✅ Partial - needed action execution clarity |
| v3.1 | Action execution pattern | ✅ Good - but too verbose |
| v3.2 | Conciseness & formatting | 🔄 Testing - should match Claude Code |
| v3.3? | TBD - if needed after v3.2 testing | - |

## Next Steps

1. **Deploy**: Restart dev server
2. **Test**: Run Casey deep-dive with RCA intake
3. **Measure**: Count lines, bullets, check for drafts
4. **Compare**: Side-by-side with Claude Code
5. **Document**: Fill in "Actual Result" in CHANGELOG.md
6. **Decide**: Close enough, or iterate to v3.3?

## Philosophy

We're converging on Claude Code's behavior through:
- **Observation**: What does Claude Code do?
- **Analysis**: Why is the app different?
- **Hypothesis**: What instruction is missing/wrong?
- **Implementation**: Add specific guidance to prompt
- **Testing**: Does it match now?
- **Iteration**: Refine based on results

Each version gets us closer. v3.2 addresses the "how to format analysis" gap that v3.1 left open.

---

**Questions?** See:
- Full details: `lib/agents/prompts/CHANGELOG.md`
- Template: `lib/agents/prompts/system-prompt.md`
- v3.1 notes: `docs/v3.1-release-notes.md`
