/**
 * Integration Tests for System Prompt Builder
 * Story 4.8: Implement System Prompt Builder with Tool Usage Instructions
 *
 * Integration Test Coverage:
 * - AC-4.8.7: System prompt tested to verify it triggers tool calls (not just text acknowledgment)
 * - Full agentic loop execution with real agent definitions
 * - Tool calling behavior with and without system prompt
 */

import { executeAgent } from '../agenticLoop';
import { getOpenAIClient } from '@/lib/openai/client';
import { getAgentById } from '@/lib/agents/loader';
import { readFileContent } from '@/lib/files/reader';
import { processCriticalActions } from '@/lib/agents/criticalActions';
import type { Agent } from '@/types';

// Mock dependencies
jest.mock('@/lib/openai/client');
jest.mock('@/lib/agents/loader');
jest.mock('@/lib/files/reader');
jest.mock('@/lib/agents/criticalActions');

const mockGetOpenAIClient = getOpenAIClient as jest.MockedFunction<
  typeof getOpenAIClient
>;
const mockGetAgentById = getAgentById as jest.MockedFunction<
  typeof getAgentById
>;
const mockReadFileContent = readFileContent as jest.MockedFunction<
  typeof readFileContent
>;
const mockProcessCriticalActions = processCriticalActions as jest.MockedFunction<
  typeof processCriticalActions
>;

describe('System Prompt Builder - Integration Tests', () => {
  const mockAgent: Agent = {
    id: 'test-agent',
    name: 'Alex',
    title: 'Requirements Facilitator',
    icon: 'ü§ù',
    path: '/agents/test-agent',
    mainFile: '/agents/test-agent/agent.md',
    fullContent: `<agent id="test-agent" name="Alex" title="Requirements Facilitator" icon="ü§ù">
  <persona>
    <role>Requirements Facilitator + User Advocate</role>
    <identity>Experienced facilitator who specializes in helping users articulate their needs.</identity>
    <communication_style>Friendly, warm, and encouraging.</communication_style>
    <principles>I believe every user has valuable insights.</principles>
  </persona>

  <critical-actions>
    <i>Load into memory {bundle-root}/config.yaml</i>
    <i>Load into memory {bundle-root}/templates/template.md</i>
  </critical-actions>

  <cmds>
    <c cmd="*help">Show numbered cmd list</c>
    <c cmd="*workflow-request" run-workflow="{bundle-root}/workflows/intake/workflow.yaml">Gather requirements</c>
  </cmds>
</agent>`,
  };

  const mockClient = {
    chat: {
      completions: {
        create: jest.fn(),
      },
    },
  };

  beforeEach(() => {
    jest.clearAllMocks();
    mockGetOpenAIClient.mockReturnValue(mockClient as any);
    mockGetAgentById.mockResolvedValue(mockAgent);
    mockProcessCriticalActions.mockResolvedValue({
      messages: [],
      config: null,
    });
    process.env.OPENAI_MODEL = 'gpt-4';
    process.env.PROJECT_ROOT = '/test/project';
  });

  describe('AC-4.8.7: System prompt triggers tool calls (not acknowledgment)', () => {
    it('should trigger read_file tool call when critical-actions has file load instruction', async () => {
      // Track tool calls
      let toolCallsMade = 0;

      // Mock file reads
      mockReadFileContent.mockResolvedValue('project_name: Test Project');

      // Iteration 1: Should call read_file tool (not just acknowledge)
      mockClient.chat.completions.create.mockResolvedValueOnce({
        choices: [
          {
            message: {
              role: 'assistant',
              content: null,
              tool_calls: [
                {
                  id: 'call_1',
                  type: 'function' as const,
                  function: {
                    name: 'read_file',
                    arguments: JSON.stringify({
                      path: '{bundle-root}/config.yaml',
                    }),
                  },
                },
              ],
            },
            finish_reason: 'tool_calls' as const,
            index: 0,
          },
        ],
        usage: { prompt_tokens: 100, completion_tokens: 50, total_tokens: 150 },
      } as any);

      toolCallsMade++;

      // Iteration 2: Final response after loading files
      mockClient.chat.completions.create.mockResolvedValueOnce({
        choices: [
          {
            message: {
              role: 'assistant',
              content:
                'I have loaded the config. Ready to assist with requirements gathering.',
              tool_calls: undefined,
            },
            finish_reason: 'stop' as const,
            index: 0,
          },
        ],
        usage: { prompt_tokens: 150, completion_tokens: 30, total_tokens: 180 },
      } as any);

      const result = await executeAgent(
        'test-agent',
        'Initialize and show your greeting',
        []
      );

      // Verify tool call was made (not just text acknowledgment)
      expect(toolCallsMade).toBeGreaterThan(0);
      expect(mockReadFileContent).toHaveBeenCalled();
      expect(result.response).toContain('loaded the config');
    });

    it('should verify system prompt includes emphatic tool usage instructions', async () => {
      // Mock OpenAI to return text acknowledgment on first call
      mockClient.chat.completions.create.mockResolvedValueOnce({
        choices: [
          {
            message: {
              role: 'assistant',
              content: null,
              tool_calls: [
                {
                  id: 'call_1',
                  type: 'function' as const,
                  function: {
                    name: 'read_file',
                    arguments: JSON.stringify({
                      path: '{bundle-root}/config.yaml',
                    }),
                  },
                },
              ],
            },
            finish_reason: 'tool_calls' as const,
            index: 0,
          },
        ],
        usage: { prompt_tokens: 200, completion_tokens: 60, total_tokens: 260 },
      } as any);

      mockReadFileContent.mockResolvedValue('project_name: Test');

      mockClient.chat.completions.create.mockResolvedValueOnce({
        choices: [
          {
            message: {
              role: 'assistant',
              content: 'Config loaded successfully',
            },
            finish_reason: 'stop' as const,
            index: 0,
          },
        ],
        usage: { prompt_tokens: 250, completion_tokens: 20, total_tokens: 270 },
      } as any);

      await executeAgent('test-agent', 'Initialize', []);

      // Check that system message was sent with emphatic instructions
      const firstCall = mockClient.chat.completions.create.mock.calls[0][0];
      const systemMessage = firstCall.messages[0];

      expect(systemMessage.role).toBe('system');
      expect(systemMessage.content).toContain(
        'When you see instructions to load files, you MUST use the read_file tool'
      );
      expect(systemMessage.content).toContain(
        'DO NOT just acknowledge file load instructions - actually call the tools'
      );
      expect(systemMessage.content).toContain('CRITICAL INSTRUCTIONS FOR TOOL USAGE');
    });

    it('should handle agent with multiple critical-actions requiring file loads', async () => {
      const agentMultipleLoads: Agent = {
        ...mockAgent,
        fullContent: `<agent id="multi-load" name="Multi" title="Multi Loader">
  <persona>
    <role>Multi File Loader</role>
    <identity>Loads multiple files</identity>
    <communication_style>Direct</communication_style>
    <principles>Load all required files</principles>
  </persona>

  <critical-actions>
    <i>Load {bundle-root}/config.yaml</i>
    <i>Load {bundle-root}/template.md</i>
    <i>Load {bundle-root}/data.json</i>
  </critical-actions>
</agent>`,
      };

      mockGetAgentById.mockResolvedValue(agentMultipleLoads);

      // First iteration: Load config
      mockClient.chat.completions.create.mockResolvedValueOnce({
        choices: [
          {
            message: {
              role: 'assistant',
              content: null,
              tool_calls: [
                {
                  id: 'call_1',
                  type: 'function' as const,
                  function: {
                    name: 'read_file',
                    arguments: JSON.stringify({
                      path: '{bundle-root}/config.yaml',
                    }),
                  },
                },
              ],
            },
            finish_reason: 'tool_calls' as const,
            index: 0,
          },
        ],
        usage: { prompt_tokens: 100, completion_tokens: 50, total_tokens: 150 },
      } as any);

      mockReadFileContent.mockResolvedValueOnce('config data');

      // Second iteration: Load template
      mockClient.chat.completions.create.mockResolvedValueOnce({
        choices: [
          {
            message: {
              role: 'assistant',
              content: null,
              tool_calls: [
                {
                  id: 'call_2',
                  type: 'function' as const,
                  function: {
                    name: 'read_file',
                    arguments: JSON.stringify({
                      path: '{bundle-root}/template.md',
                    }),
                  },
                },
              ],
            },
            finish_reason: 'tool_calls' as const,
            index: 0,
          },
        ],
        usage: { prompt_tokens: 150, completion_tokens: 50, total_tokens: 200 },
      } as any);

      mockReadFileContent.mockResolvedValueOnce('template content');

      // Third iteration: Load data
      mockClient.chat.completions.create.mockResolvedValueOnce({
        choices: [
          {
            message: {
              role: 'assistant',
              content: null,
              tool_calls: [
                {
                  id: 'call_3',
                  type: 'function' as const,
                  function: {
                    name: 'read_file',
                    arguments: JSON.stringify({
                      path: '{bundle-root}/data.json',
                    }),
                  },
                },
              ],
            },
            finish_reason: 'tool_calls' as const,
            index: 0,
          },
        ],
        usage: { prompt_tokens: 200, completion_tokens: 50, total_tokens: 250 },
      } as any);

      mockReadFileContent.mockResolvedValueOnce('{"data": "value"}');

      // Final iteration: Response
      mockClient.chat.completions.create.mockResolvedValueOnce({
        choices: [
          {
            message: {
              role: 'assistant',
              content: 'All files loaded successfully',
            },
            finish_reason: 'stop' as const,
            index: 0,
          },
        ],
        usage: { prompt_tokens: 250, completion_tokens: 20, total_tokens: 270 },
      } as any);

      const result = await executeAgent('multi-load', 'Initialize', []);

      // Verify all three files were loaded via tool calls
      expect(mockReadFileContent).toHaveBeenCalledTimes(3);
      expect(result.iterations).toBe(4); // 3 tool call iterations + 1 final response
      expect(result.response).toContain('All files loaded successfully');
    });

    it('should test with different agent types (with/without commands section) - AC-4.8.7', async () => {
      const agentNoCommands: Agent = {
        ...mockAgent,
        id: 'no-commands',
        name: 'Simple',
        title: 'Simple Agent',
        fullContent: `<agent id="no-commands" name="Simple" title="Simple Agent">
  <persona>
    <role>Simple role</role>
    <identity>Simple identity</identity>
    <communication_style>Simple style</communication_style>
    <principles>Simple principles</principles>
  </persona>
</agent>`,
      };

      mockGetAgentById.mockResolvedValue(agentNoCommands);

      mockClient.chat.completions.create.mockResolvedValueOnce({
        choices: [
          {
            message: {
              role: 'assistant',
              content: 'Hello, I am ready to help.',
            },
            finish_reason: 'stop' as const,
            index: 0,
          },
        ],
        usage: { prompt_tokens: 100, completion_tokens: 20, total_tokens: 120 },
      } as any);

      const result = await executeAgent('no-commands', 'Say hello', []);

      // Verify system prompt was still generated correctly
      const firstCall = mockClient.chat.completions.create.mock.calls[0][0];
      const systemMessage = firstCall.messages[0];

      expect(systemMessage.role).toBe('system');
      expect(systemMessage.content).toContain('You are Simple, Simple Agent');
      expect(systemMessage.content).toContain('Simple role');
      expect(systemMessage.content).not.toContain('AVAILABLE COMMANDS:');
      expect(result.response).toContain('Hello');
    });
  });
});
